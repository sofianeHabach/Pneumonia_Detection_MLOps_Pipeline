name: ML Pipeline

on:
  workflow_dispatch:
  push:
    branches:
      - main

jobs:
  ml_pipeline:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python 3.9.20
      uses: actions/setup-python@v4
      with:
        python-version: '3.9.20'
      
    - name: Install Graphviz
      run: |
          sudo apt-get update
          sudo apt-get install -y graphviz

    - name: Install DVC and dependencies
      run: |
        python -m pip install --upgrade pip
        pip uninstall -y protobuf
        pip install protobuf==3.19.6 --no-cache-dir
        pip install -r requirements.txt
        python -c "import google.protobuf; print('protobuf version:', google.protobuf.__version__)"

    - name: Pull data from DVC remote (if needed)
      run: dvc pull || echo "Pas de remote configuré pour DVC."
    
    - name: Download and install ngrok
      run: |
        curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null
        echo "deb https://ngrok-agent.s3.amazonaws.com buster main" | sudo tee /etc/apt/sources.list.d/ngrok.list
        sudo apt update && sudo apt install ngrok

    - name: Start MLflow server and ngrok tunnel
      run: |
        nohup mlflow ui --host 0.0.0.0 --port 5000 > mlflow.log 2>&1 &
        sleep 10  # attendre que mlflow démarre
        nohup ngrok http 5000 > ngrok.log 2>&1 &
        sleep 10  # attendre que ngrok démarre

    - name: Display ngrok public URL
      run: |
        curl http://localhost:4040/api/tunnels | jq -r '.tunnels[0].public_url'


    - name: Run data preprocessing
      run: |
        python data_preprocessing.py
        dvc add data/pneumonia_dataset.csv
        git add data/pneumonia_dataset.csv.dvc
        git config --global user.name "github-actions"
        git config --global user.email "action@github.com"
        git diff --quiet || git commit -m "Track dataset with DVC after preprocessing"

    - name: Split data
      run: |
        python train_test_split.py
        dvc add data/splits/train_split.csv
        dvc add data/splits/valid_split.csv
        dvc add data/splits/test_split.csv
        git add data/splits/*.dvc
        git diff --quiet || git commit -m "Track data splits with DVC"

    - name: Train model
      run: |
        python model_training.py
        dvc add -f outputs/models/Enhanced_model_V2.keras
        git add -f outputs/models/Enhanced_model_V2.keras.dvc
        git diff --quiet || git commit -m "Track trained model with DVC"

    - name: Evaluate model
      run: python model_evaluation.py

    - name: Validate model
      run: |
        python -c "
        import json
        with open('outputs/results/classification_report.json') as f:
            report = json.load(f)
        f1_normal = report['NORMAL']['f1-score']
        f1_pneumonia = report['PNEUMONIA']['f1-score']
        print(f'F1-score NORMAL: {f1_normal}')
        print(f'F1-score PNEUMONIA: {f1_pneumonia}')
        if f1_normal < 0.9 or f1_pneumonia < 0.9:
            print('Modèle rejeté : F1-score trop bas')
        else:
            print('Modèle validé !')
        "

    - name: Archive artifacts
      uses: actions/upload-artifact@v4
      with:
        name: model-artifacts
        path: |
          **/*.txt
          **/*.png
          **/*.csv
          **/*.keras
